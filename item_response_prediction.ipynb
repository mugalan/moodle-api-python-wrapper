{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8xF7bMMUHgTJmLesYX5ZY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mugalan/item-response-prediction/blob/main/item_response_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Overview"
      ],
      "metadata": {
        "id": "r9K-WKVTC6uw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A high-level, production-friendly wrapper for adaptive item recommendation and Bayesian ability estimation over (\\theta \\in [0,1]), built on top of:\n",
        "\n",
        "* `Bayesian2PL` — grid-based Bayesian estimator for 2PL and ideal-point likelihoods\n",
        "* `ItemizedBayesian2PL` — convenience helpers for item dict pools\n",
        "* `ItemResponsePredictionRunner` — orchestration (posterior, bandit head, plots)\n",
        "\n",
        "`ItemResponsePrediction` exposes a clean, minimal API for:\n",
        "\n",
        "* **Recommending the next item** to present based on your chosen engine/policy\n",
        "* **Updating the posterior** and bandit statistics from an observed response\n",
        "* **Resetting/replacing the item pool** (with optional plots)\n",
        "\n",
        "---\n",
        "\n",
        "## Features\n",
        "\n",
        "* **Two likelihoods**\n",
        "\n",
        "  * 2PL logistic (parameters (a>0), (b \\in [0,1]))\n",
        "  * Ideal-point logistic (parameters (\\kappa>0), (\\gamma), (b \\in [0,1]))\n",
        "* **Engines**: `bayes`, `bandit`, `hybrid`\n",
        "* **Policies** (Bayes): `thompson`, `greedy`, `ucb`, `bayesucb`, `max_info`, `closest_b`\n",
        "* **Bandit strategies** (via runner): discounted UCB and Beta variants\n",
        "* **Posterior-predictive scoring** of items\n",
        "* **Exposure caps** (temporarily mask over-exposed items)\n",
        "* **Plotly visualizations** for posterior and per-item curves\n",
        "* **Audit-friendly metadata** returned with each call\n",
        "\n",
        "---\n",
        "\n",
        "## Installation & Requirements\n",
        "\n",
        "**Requirements**\n",
        "\n",
        "* Python ≥ 3.9\n",
        "* `numpy` (required)\n",
        "* `plotly` (optional, only for plotting utilities)\n",
        "\n",
        "**Install (from GitHub)**\n",
        "\n",
        "```bash\n",
        "pip install \"git+https://github.com/mugalan/item-response-prediction.git\"\n",
        "```\n",
        "\n",
        "**Optional: plotting support**\n",
        "\n",
        "```bash\n",
        "pip install plotly\n",
        "```\n",
        "\n",
        "> If your package defines an extra named `plotting`, you can alternatively do:\n",
        ">\n",
        "> ```bash\n",
        "> pip install \"git+https://github.com/mugalan/item-response-prediction.git#egg=item-response-prediction[plotting]\"\n",
        "> ```\n",
        "\n",
        "**Import**\n",
        "\n",
        "```python\n",
        "from item_response_prediction import ItemResponsePrediction\n",
        "```\n",
        "\n",
        "**Colab tip**\n",
        "After installing, run the import in a new cell (or `Runtime > Restart session`) so the environment picks up the newly installed package.\n",
        "\n",
        "**Developer (editable) install**\n",
        "\n",
        "```bash\n",
        "git clone https://github.com/mugalan/item-response-prediction.git\n",
        "cd item-response-prediction\n",
        "pip install -e .\n",
        "```\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Concepts at a Glance\n",
        "\n",
        "* **Ability ((\\theta))**: Learner/user latent skill; supported on `[0,1]` with a Beta prior.\n",
        "* **Item parameters**\n",
        "\n",
        "  * 2PL: difficulty `b ∈ [0,1]`, discrimination `a > 0`.\n",
        "  * Ideal-point: location `b ∈ [0,1]`, sharpness `κ > 0`, height/offset `γ`.\n",
        "* **Posterior**: Grid approximation (default 1001 points) with numerically safe log-space normalization.\n",
        "* **Recommendation**: Combines Bayesian CAT-style scoring and/or bandit exploration; hybrid mixes both.\n",
        "\n",
        "---\n",
        "\n",
        "## Quick Start\n",
        "\n",
        "```python\n",
        "from item_response_prediction import ItemResponsePrediction\n",
        "\n",
        "import json\n",
        "from IPython.display import display, HTML\n",
        "items = [\n",
        "    {\"label\": \"Q1\", \"b\": 0.30, \"kappa\": 40.0, \"gamma\": 0.0},\n",
        "    {\"label\": \"Q2\", \"b\": 0.45, \"kappa\": 50.0, \"gamma\": 0.0},\n",
        "    {\"label\": \"Q3\", \"b\": 0.60, \"kappa\": 60.0, \"gamma\": 0.0},\n",
        "]\n",
        "\n",
        "irp = ItemResponsePrediction(\n",
        "    likelihood=\"ideal\",      # or \"2pl\"\n",
        "    engine=\"hybrid\",         # \"bayes\" | \"bandit\" | \"hybrid\"\n",
        "    policy=\"ucb\",            # used by bayes engine\n",
        "    hybrid_eta=0.5,\n",
        "    items=items,\n",
        ")\n",
        "\n",
        "# 1) Ask for a recommendation (does NOT modify state)\n",
        "rec = irp.recommend()\n",
        "print(rec[\"response\"][\"meta_data\"][\"item\"])  # the recommended item dict\n",
        "\n",
        "# 2) Record an observed outcome for that label (updates posterior & bandit)\n",
        "label = rec[\"response\"][\"meta_data\"][\"item\"][\"label\"]\n",
        "step_out = irp.update_estimator(label=label, outcome=1)  # 1=correct/positive, 0=incorrect/negative\n",
        "figure=HTML(json.loads(step_out['response']['data']).get('figure'))\n",
        "display(figure)\n",
        "\n",
        "# 3) Repeat recommend → update loop\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Data Schemas\n",
        "\n",
        "### Item dictionaries (recommended)\n",
        "\n",
        "* **2PL**: `{\"label\": str, \"b\": float in [0,1], \"a\": float > 0}`\n",
        "* **Ideal-point**: `{\"label\": str, \"b\": float in [0,1], \"kappa\": float > 0, \"gamma\": float}`\n",
        "\n",
        "### Legacy arrays (also supported by the runner)\n",
        "\n",
        "* Provide `B` (and `A` or `K`/`Gm` depending on the likelihood). `ItemResponsePrediction` prefers item dicts.\n",
        "\n",
        "---\n",
        "\n",
        "## API Reference: `ItemResponsePrediction`\n",
        "\n",
        "### Constructor\n",
        "\n",
        "```python\n",
        "ItemResponsePrediction(\n",
        "    *,\n",
        "    grid_points: int = 1001,\n",
        "    alpha: float = 1.0,\n",
        "    beta: float = 1.0,\n",
        "    default_a: float = 4.0,\n",
        "    likelihood: str = \"ideal\",\n",
        "    engine: str = \"hybrid\",\n",
        "    policy: str = \"ucb\",\n",
        "    bandit_discount: float = 0.97,\n",
        "    bandit_c: float = 0.50,\n",
        "    bandit_alpha0: float = 1.0,\n",
        "    bandit_beta0: float = 1.0,\n",
        "    hybrid_eta: float = 0.5,\n",
        "    max_exposures_per_item: int = 0,\n",
        "    items: Optional[Sequence[dict]] = None,\n",
        "    B: Optional[Sequence[float]] = None,\n",
        "    A: Optional[Sequence[float]] = None,\n",
        "    K: Optional[Sequence[float]] = None,\n",
        "    Gm: Optional[Sequence[float]] = None,\n",
        "    estimator: Optional[Any] = None,\n",
        ")\n",
        "```\n",
        "\n",
        "* **`likelihood`**: `\"2pl\"` or `\"ideal\"`.\n",
        "* **`engine`**: `\"bayes\"`, `\"bandit\"`, or `\"hybrid\"`.\n",
        "* **`policy`** (Bayes engine): `\"thompson\" | \"greedy\" | \"ucb\" | \"bayesucb\" | \"max_info\" | \"closest_b\"`.\n",
        "* **`max_exposures_per_item`**: `0` means unlimited; `>0` temporarily masks over-exposed items.\n",
        "\n",
        "### `recommend()` → dict\n",
        "\n",
        "Returns an envelope with `status`, `message`, and `response`:\n",
        "\n",
        "```python\n",
        "{\n",
        "  \"status\": \"success\",\n",
        "  \"response\": {\n",
        "    \"meta_data\": {\n",
        "      \"step\": int,\n",
        "      \"idx\": int,\n",
        "      \"item\": { ... },\n",
        "      \"p_pred_before\": float,\n",
        "      \"exposures\": int,\n",
        "      \"avg_reward\": float,\n",
        "      \"reward_sum\": float,\n",
        "      \"trials\": int,\n",
        "      \"picker_engine\": \"bayes\" | \"bandit\" | \"hybrid\",\n",
        "      \"bayes_index\": Optional[int],\n",
        "      \"bandit_index\": Optional[int],\n",
        "      ...\n",
        "    },\n",
        "    \"data\": {\"figure\": \"\"},\n",
        "    \"message\": str\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "> Side-effect free: does not update posterior or bandit stats.\n",
        "\n",
        "### `update_estimator(label: str, outcome: int, show_plots: bool=False)` → dict\n",
        "\n",
        "* Updates the posterior with the observed binary outcome for the given item `label`.\n",
        "* Records the outcome into the bandit head (discounted counts or Beta posterior depending on strategy).\n",
        "* Returns an envelope including a Plotly HTML string of the updated (\\theta) posterior.\n",
        "\n",
        "### `reset_estimator(alpha=None, beta=None, clear_bandit=True, clear_exposures=True, items=None, likelihood=None)` → dict\n",
        "\n",
        "* **Soft reset**: when only `alpha/beta` change (and no new items), the grid estimator is reset to the prior.\n",
        "* **Full rebuild**: when `items` are provided; installs new pool, clears bandit state and exposures.\n",
        "* Returns an envelope with metadata and (if items provided) a Plotly HTML figure showing per-item probability profiles.\n",
        "\n",
        "---\n",
        "\n",
        "## Engines & Policies (Behavioral Summary)\n",
        "\n",
        "### Bayes engine\n",
        "\n",
        "Scores each candidate by posterior-expected success (or related info):\n",
        "\n",
        "* `greedy`: maximize expected success\n",
        "* `ucb`: expected success + κ × posterior std\n",
        "* `thompson`: sample (\\theta) from the posterior; pick best given that draw\n",
        "* `bayesucb`: quantile-based optimistic selection w.r.t. (\\theta) or (p)\n",
        "* `max_info`: maximize Fisher information under the posterior mixture\n",
        "* `closest_b`: heuristic — pick item with `b` closest to current (E[\\theta])\n",
        "\n",
        "### Bandit engine\n",
        "\n",
        "Tracks *arm-level* discounted rewards and chooses with:\n",
        "\n",
        "* Discounted UCB\n",
        "* Beta-TS / Beta-UCB / Beta-mean variants (effective α/β updated with discounting)\n",
        "\n",
        "### Hybrid engine\n",
        "\n",
        "Convex combination of normalized Bayes and Bandit scores: `mix = (1-η)*Bayes + η*Bandit`.\n",
        "\n",
        "---\n",
        "\n",
        "## Likelihood Details\n",
        "\n",
        "### 2PL Logistic\n",
        "\n",
        "[ p(y=1 \\mid \\theta, a, b) = \\sigma\\big(a(\\theta - b)\\big) ]\n",
        "\n",
        "* `a > 0` (discrimination); `b ∈ [0,1]` (difficulty)\n",
        "\n",
        "### Ideal-Point Logistic\n",
        "\n",
        "[ p(y=1 \\mid \\theta, \\kappa, \\gamma, b) = \\sigma\\big(\\gamma - \\kappa (\\theta - b)^2\\big) ]\n",
        "\n",
        "* `κ > 0` (sharpness); `γ` (height/offset); `b ∈ [0,1]`\n",
        "\n",
        "Both are numerically stabilized by clipping logits and probabilities.\n",
        "\n",
        "---\n",
        "\n",
        "## End-to-End Examples\n",
        "\n",
        "### A. Ideal-point, item dict pool\n",
        "\n",
        "```python\n",
        "import json\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "items = [\n",
        "    {\"label\": \"I1\", \"b\": 0.25, \"kappa\": 35.0, \"gamma\": 0.0},\n",
        "    {\"label\": \"I2\", \"b\": 0.50, \"kappa\": 50.0, \"gamma\": 0.0},\n",
        "    {\"label\": \"I3\", \"b\": 0.75, \"kappa\": 70.0, \"gamma\": 0.0},\n",
        "]\n",
        "\n",
        "irp = ItemResponsePrediction(likelihood=\"ideal\", engine=\"hybrid\", policy=\"ucb\", items=items)\n",
        "\n",
        "for t in range(5):\n",
        "    rec = irp.recommend()\n",
        "    label = rec[\"response\"][\"meta_data\"][\"item\"][\"label\"]\n",
        "\n",
        "    import random\n",
        "    y = 1 if random.random() < (0.8 if label == \"I2\" else 0.5) else 0\n",
        "\n",
        "    out = irp.update_estimator(label, y)\n",
        "    fig_html = json.loads(out[\"response\"][\"data\"])[\"figure\"]\n",
        "    display(HTML(fig_html))             # <-- actually display it\n",
        "    print(out[\"response\"][\"meta_data\"][\"theta_hat\"],\n",
        "          out[\"response\"][\"meta_data\"][\"avg_reward\"])\n",
        "\n",
        "```\n",
        "\n",
        "### B. 2PL, item dict pool with discrimination\n",
        "\n",
        "```python\n",
        "import json\n",
        "from IPython.display import display, HTML\n",
        "items_2pl = [\n",
        "    {\"label\": \"Q1\", \"b\": 0.35, \"a\": 3.5},\n",
        "    {\"label\": \"Q2\", \"b\": 0.50, \"a\": 4.0},\n",
        "    {\"label\": \"Q3\", \"b\": 0.70, \"a\": 5.0},\n",
        "]\n",
        "\n",
        "irp2 = ItemResponsePrediction(likelihood=\"2pl\", engine=\"bayes\", policy=\"thompson\", items=items_2pl)\n",
        "rec = irp2.recommend()\n",
        "print(\"Recommend:\", rec[\"response\"][\"meta_data\"][\"item\"])  # inspect choice\n",
        "\n",
        "# Suppose user answered Q2 incorrectly (0)\n",
        "out = irp2.update_estimator(\"Q2\", 0)\n",
        "fig_html = json.loads(out[\"response\"][\"data\"])[\"figure\"]\n",
        "display(HTML(fig_html))             \n",
        "print(\"theta(mean):\", out[\"response\"][\"meta_data\"][\"theta_hat\"])\n",
        "```\n",
        "\n",
        "### C. Reset with a new pool and prior\n",
        "\n",
        "```python\n",
        "new_items = [\n",
        "    {\"label\": \"N1\", \"b\": 0.40, \"kappa\": 50.0, \"gamma\": 0.0},\n",
        "    {\"label\": \"N2\", \"b\": 0.60, \"kappa\": 50.0, \"gamma\": 0.0},\n",
        "]\n",
        "\n",
        "r = irp.reset_estimator(alpha=2.0, beta=2.0, items=new_items, likelihood=\"ideal\")\n",
        "print(r[\"status\"], r[\"response\"][\"meta_data\"][\"posterior_summary\"])\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Tips & Best Practices\n",
        "\n",
        "* Use **item dictionaries** with explicit labels — simpler and safer than managing parallel arrays.\n",
        "* For early-stage users, prefer **wider priors** (e.g., `alpha=1, beta=1`) and a **hybrid** engine for balanced exploration.\n",
        "* If you want faster convergence when the pool is calibrated, try **Bayes `max_info`** or **`ucb`**.\n",
        "* Apply a **reasonable exposure cap** in large pools (e.g., `max_exposures_per_item=2`) to avoid overusing the same item.\n",
        "* Inspect the returned Plotly HTML to sanity-check the posterior evolution during development.\n",
        "\n",
        "---\n",
        "\n",
        "## Numerical Notes\n",
        "\n",
        "* Logits and probabilities are clipped to avoid under/overflow.\n",
        "* Posterior normalization uses the trapezoidal rule; set `grid_points ≥ 101` (default 1001).\n",
        "* The Beta prior is parameterized as `Beta(alpha, beta)` on `[0,1]`.\n",
        "\n",
        "---\n",
        "\n",
        "## Troubleshooting\n",
        "\n",
        "* **ValueError: item keys missing** — ensure your items match the likelihood schema.\n",
        "* **All candidates masked** — if using `max_exposures_per_item`, the runner will temporarily unmask all if everything is at cap.\n",
        "* **Posterior looks flat** — try increasing `grid_points`, narrowing the prior, or presenting more discriminating items.\n",
        "* **No Plotly output** — install `plotly` and ensure your environment can render/save HTML snippets.\n",
        "\n",
        "---\n",
        "\n",
        "## FAQ\n",
        "\n",
        "**Q: Does `recommend()` update the posterior?**\n",
        "A: No. It is side-effect free. Call `update_estimator(label, outcome)` after the user responds.\n",
        "\n",
        "**Q: Can I plug in my own estimator?**\n",
        "A: Yes. You can pass a pre-built `Bayesian2PL`-compatible estimator to the runner (advanced use). The `ItemResponsePrediction` wrapper focuses on the common case with its own internal runner.\n",
        "\n",
        "**Q: How do I run pure bandit exploration?**\n",
        "A: Initialize with `engine=\"bandit\"` (the `policy` is ignored in that case) and tune `bandit_discount`, `bandit_c`, or pick a Beta-based strategy via the runner if you need.\n",
        "\n",
        "---\n",
        "\n",
        "## License\n",
        "\n",
        "MIT Copyright (c) 2025 Sanjeeva Maithripala\n"
      ],
      "metadata": {
        "id": "eYgu7KhSC9eN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nlyqm9y6Lcqk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Item Response Prediction — Theoretical Procedure"
      ],
      "metadata": {
        "id": "cHCmFMSEQyQE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Goal.** Adaptively select items and update a user's latent ability $\\theta \\in [0,1]$ using Bayesian inference (2PL or ideal-point) and optional bandit exploration.\n",
        "\n",
        "---\n",
        "\n",
        "### Model & Prior\n",
        "\n",
        "We model the user's ability $\\theta$ with a Beta prior:\n",
        "$$\n",
        "\\begin{align}\n",
        "\\theta &\\in [0,1], \\\\\n",
        "\\theta &\\sim \\mathrm{Beta}(\\alpha,\\beta), \\\\\n",
        "\\log p(\\theta) &= (\\alpha-1)\\log \\theta + (\\beta-1)\\log(1-\\theta) + \\mathrm{const}.\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "For numerical stability we approximate on a grid $\\left\\{\\theta_g\\right\\}_{g=1}^G$ and work in log-space.\n",
        "\n",
        "---\n",
        "\n",
        "### Likelihoods\n",
        "\n",
        "**2PL logistic**\n",
        "$$\n",
        "\\begin{align}\n",
        "p_i(\\theta) &= \\sigma\\big(a_i(\\theta - b_i)\\big), \\quad a_i>0, b_i\\in[0,1], \\\\\n",
        "\\sigma(x) &= \\frac{1}{1+e^{-x}}.\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "**Ideal-point logistic**\n",
        "$$\n",
        "\\begin{align}\n",
        "p_i(\\theta) &= \\sigma\\big(\\gamma_i - \\kappa_i(\\theta - b_i)^2\\big),\n",
        "\\quad \\kappa_i>0,\\: b_i\\in[0,1],\\: \\gamma_i\\in\\mathbb{R}.\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Given observed outcome $y_i \\in \\left\\{0,1\\right\\}$ for item $i$, the per-item log-likelihood on the grid is:\n",
        "$$\n",
        "\\begin{align}\n",
        "\\ell_i(\\theta) &= y_i \\log p_i(\\theta) + (1-y_i)\\log\\big(1-p_i(\\theta)\\big).\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "### Posterior Update (batch or single)\n",
        "\n",
        "For a batch $\\mathscr{D}={(i,y_i)}$:\n",
        "$$\n",
        "\\begin{align}\n",
        "\\log p(\\theta \\mid \\mathscr{D})\n",
        "&\\propto \\log p(\\theta) + \\sum_{(i,y_i)\\in\\mathscr{D}} \\ell_i(\\theta).\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Normalize on the grid by exponentiation and numerical integration (e.g., trapezoidal rule):\n",
        "$$\n",
        "\\begin{align}\n",
        "w(\\theta_g) &= \\exp\\Big(\\log p(\\theta_g \\mid \\mathscr{D}) - m\\Big),\\quad\n",
        "m=\\max_g \\log p(\\theta_g \\mid \\mathscr{D}),\\\\\n",
        "Z &= \\sum_g w(\\theta_g)\\Delta_g, \\\\\n",
        "p(\\theta_g \\mid \\mathscr{D}) &= \\frac{w(\\theta_g)}{Z}.\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Posterior summaries:\n",
        "$$\n",
        "\\begin{align}\n",
        "\\widehat\\theta_{\\text{mean}} &= \\sum_g \\theta_g p(\\theta_g \\mid \\mathscr{D}),\\Delta_g, \\\\\n",
        "\\widehat\\theta_{\\text{MAP}}  &= \\arg\\max_{\\theta_g} p(\\theta_g \\mid \\mathscr{D}), \\\\\n",
        "\\text{Median/CI} &\\text{ via CDF from cumulative sums over the grid.}\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "### Posterior-Predictive Success (Scoring Candidates)\n",
        "\n",
        "For a candidate item $j$ with parameters $(a_j,b_j)$ or $(\\kappa_j,\\gamma_j,b_j)$:\n",
        "$$\n",
        "\\begin{align}\n",
        "\\mathbb{E}[p_j]\n",
        "&= \\int p_j(\\theta) p(\\theta \\mid \\mathscr{D}) d\\theta\n",
        "\\:\\approx \\sum_g p_j(\\theta_g) p(\\theta_g \\mid \\mathscr{D}) \\Delta_g \\\\\n",
        "\\mathrm{Var}[p_j]\n",
        "&= \\mathbb{E}[p_j^2]-\\mathbb{E}[p_j]^2.\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "### Bayesian Policies\n",
        "\n",
        "**Greedy**\n",
        "$$\n",
        "\\begin{align}\n",
        "\\text{score}_j^{\\text{greedy}} &= \\mathbb{E}[p_j].\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "**UCB (posterior-std bonus)**\n",
        "$$\n",
        "\\begin{align}\n",
        "\\text{score}_j^{\\text{ucb}} &= \\mathbb{E}[p_j] + \\kappa \\sqrt{\\mathrm{Var}[p_j]}.\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "**Thompson Sampling**\n",
        "$$\n",
        "\\begin{align}\n",
        "\\widetilde{\\theta} &\\sim p(\\theta \\mid \\mathscr{D}), \\\\\n",
        "\\text{pick } j^* &= \\arg\\max_j  p_j(\\widetilde{\\theta}).\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "**BayesUCB (quantile-based optimism)**\n",
        "$$\n",
        "\\begin{align}\n",
        "q &\\in (0,1), \\\\\n",
        "\\text{score}_j^{\\text{bayesucb}}\n",
        "&= \\text{(q)-quantile of } {p_j(\\theta_g)}\\text{ under } p(\\theta_g \\mid \\mathscr{D}).\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "**Max-Information (expected Fisher information under the posterior mixture)**\n",
        "\n",
        "For 2PL:\n",
        "$$\n",
        "\\begin{align}\n",
        "\\frac{\\partial}{\\partial \\theta}\\big(a_j(\\theta-b_j)\\big) &= a_j, \\\\\n",
        "\\mathscr{I}_j(\\theta) &= \\big(a_j\\big)^2 p_j(\\theta)\\big(1-p_j(\\theta)\\big), \\\\\n",
        "\\text{score}_j^{\\text{info}} &= \\int \\mathscr{I}_j(\\theta) p(\\theta \\mid \\mathscr{D}) d\\theta.\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "For ideal-point:\n",
        "$$\n",
        "\\begin{align}\n",
        "\\text{logit}_j(\\theta) &= \\gamma_j - \\kappa_j(\\theta-b_j)^2, \\\\\n",
        "\\frac{\\partial}{\\partial \\theta}\\text{logit}_j(\\theta) &= -2\\kappa_j(\\theta-b_j), \\\\\n",
        "\\mathscr{I}_j(\\theta) &= \\big(-2\\kappa_j(\\theta-b_j)\\big)^2 p_j(\\theta)\\big(1-p_j(\\theta)\\big), \\\\\n",
        "\\text{score}_j^{\\text{info}} &= \\int \\mathscr{I}_j(\\theta) p(\\theta \\mid \\mathscr{D}) d\\theta.\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "**Closest-(b) (heuristic)**\n",
        "$$\n",
        "\\begin{align}\n",
        "\\text{score}_j^{\\text{closest}} &= -\\left| b_j - \\mathbb{E}[\\theta] \\right|.\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "### Bandit Head (Discounted UCB / Beta Variants)\n",
        "\n",
        "Exponential discounting with $\\lambda \\in (0,1]$ for each arm $j$:\n",
        "$$\n",
        "\\begin{align}\n",
        "S_j &\\leftarrow \\lambda^{\\Delta t}S_j + y, \\\\\n",
        "N_j &\\leftarrow \\lambda^{\\Delta t}N_j + 1.\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "**Discounted UCB**\n",
        "$$\n",
        "\\begin{align}\n",
        "\\widehat{\\mu}_j &= \\frac{\\alpha_0 + S_j}{\\alpha_0 + \\beta_0 + N_j}, \\\\\n",
        "\\text{score}_j^{\\text{d-ucb}} &= \\widehat{\\mu}_j + \\sqrt{c \\frac{\\log(1+t)}{\\max(N_j,\\varepsilon)}}.\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "**Beta-based (effective parameters with discount)**\n",
        "$$\n",
        "\\begin{align}\n",
        "\\alpha_j &\\leftarrow \\lambda^{\\Delta t} \\alpha_j + y, \\\\\n",
        "\\beta_j  &\\leftarrow \\lambda^{\\Delta t} \\beta_j  + (1-y).\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "* **Beta-mean**: $\\text{score}_j = \\dfrac{\\alpha_j}{\\alpha_j + \\beta_j}$.\n",
        "* **Beta-UCB**: $\\text{score}_j = \\mu_j + z_q \\sigma_j$ using normal approx of Beta.\n",
        "* **Beta-TS**: sample $\\widetilde{\\mu}_j \\sim \\mathrm{Beta}(\\alpha_j,\\beta_j)$, pick $\\arg\\max_j \\widetilde{\\mu}_j$.\n",
        "\n",
        "---\n",
        "\n",
        "### Hybrid Mixing\n",
        "\n",
        "Combine Bayes and Bandit scores after min–max normalization:\n",
        "$$\n",
        "\\begin{align}\n",
        "\\text{score}_j^{\\text{hybrid}} &= (1-\\eta)\\widetilde{\\text{score}}^{\\text{bayes}}_j + \\eta \\widetilde{\\text{score}}^{\\text{bandit}}_j, \\\\\n",
        "\\eta &\\in [0,1].\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "### One Step of the Procedure\n",
        "\n",
        "1. **Recommend**\n",
        "   Compute scores ${\\text{score}*j}$ for all candidates (respect exposure caps), choose\n",
        "   $$\n",
        "   \\begin{align}\n",
        "   j^* &= \\arg\\max_j \\text{score}*j.\n",
        "   \\end{align}\n",
        "   $$\n",
        "   Report $p^*_{\\text{pred}} = \\mathbb{E}[p^*_{j^*}]).\n",
        "\n",
        "2. **Observe Outcome** $y \\in {0,1}$ for $j^*$.\n",
        "\n",
        "3. **Bayesian Update**\n",
        "   Update $\\log p(\\theta \\mid \\mathscr{D})$ with $\\ell_{j^*}(\\theta)$ and renormalize.\n",
        "\n",
        "4. **Bandit Update**\n",
        "   Update $(S_{j^*},N_{j^*})$ and/or $(\\alpha_{j^*},\\beta_{j^*})$ with discount $\\lambda$.\n",
        "\n",
        "5. **Bookkeeping**\n",
        "   Increment exposure count for $j^*$; recompute summaries $\\widehat\\theta_{\\text{mean}}, \\text{CI}$, etc.\n",
        "\n",
        "---\n",
        "\n",
        "### Numerical Stabilization (Implementation Notes)\n",
        "\n",
        "* Clip logits to ([-50, 50]) and probabilities to $[\\varepsilon, 1-\\varepsilon]$.\n",
        "* Work in log-space for the posterior accumulator before normalization.\n",
        "* Use a sufficiently fine grid $G \\ge 101$ (default $G=1001$) and trapezoidal integration.\n"
      ],
      "metadata": {
        "id": "Jb-WodFbQ29U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Python Package Installation"
      ],
      "metadata": {
        "id": "YrtRk0LyOwTc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json, csv\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import graphviz\n",
        "from IPython.display import display, Image\n",
        "\n",
        "from pydantic import BaseModel, ValidationError, field_validator\n",
        "from typing import Optional"
      ],
      "metadata": {
        "id": "bBMu65ZtYn0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"git+https://github.com/mugalan/item-response-prediction.git\""
      ],
      "metadata": {
        "id": "4vfZQbWiYuT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Quick start example"
      ],
      "metadata": {
        "id": "jPITG-c3N1nL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from IPython.display import display, HTML\n",
        "items = [\n",
        "    {\"label\": \"Q1\", \"b\": 0.30, \"kappa\": 40.0, \"gamma\": 0.0},\n",
        "    {\"label\": \"Q2\", \"b\": 0.45, \"kappa\": 50.0, \"gamma\": 0.0},\n",
        "    {\"label\": \"Q3\", \"b\": 0.60, \"kappa\": 60.0, \"gamma\": 0.0},\n",
        "]\n",
        "\n",
        "irp = ItemResponsePrediction(\n",
        "    likelihood=\"ideal\",      # or \"2pl\"\n",
        "    engine=\"hybrid\",         # \"bayes\" | \"bandit\" | \"hybrid\"\n",
        "    policy=\"ucb\",            # used by bayes engine\n",
        "    hybrid_eta=0.5,\n",
        "    items=items,\n",
        ")\n",
        "\n",
        "# 1) Ask for a recommendation (does NOT modify state)\n",
        "rec = irp.recommend()\n",
        "print(rec[\"response\"][\"meta_data\"][\"item\"])  # the recommended item dict\n",
        "\n",
        "# 2) Record an observed outcome for that label (updates posterior & bandit)\n",
        "label = rec[\"response\"][\"meta_data\"][\"item\"][\"label\"]\n",
        "step_out = irp.update_estimator(label=label, outcome=1)  # 1=correct/positive, 0=incorrect/negative\n",
        "figure=HTML(json.loads(step_out['response']['data']).get('figure'))\n",
        "display(figure)"
      ],
      "metadata": {
        "id": "GPDPK57tbEy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ideal-point, item dict pool"
      ],
      "metadata": {
        "id": "stWIf-qhO5QF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "items = [\n",
        "    {\"label\": \"I1\", \"b\": 0.25, \"kappa\": 35.0, \"gamma\": 0.0},\n",
        "    {\"label\": \"I2\", \"b\": 0.50, \"kappa\": 50.0, \"gamma\": 0.0},\n",
        "    {\"label\": \"I3\", \"b\": 0.75, \"kappa\": 70.0, \"gamma\": 0.0},\n",
        "]\n",
        "\n",
        "irp = ItemResponsePrediction(likelihood=\"ideal\", engine=\"hybrid\", policy=\"ucb\", items=items)\n",
        "\n",
        "for t in range(5):\n",
        "    rec = irp.recommend()\n",
        "    label = rec[\"response\"][\"meta_data\"][\"item\"][\"label\"]\n",
        "\n",
        "    import random\n",
        "    y = 1 if random.random() < (0.8 if label == \"I2\" else 0.5) else 0\n",
        "\n",
        "    out = irp.update_estimator(label, y)\n",
        "    fig_html = json.loads(out[\"response\"][\"data\"])[\"figure\"]\n",
        "    display(HTML(fig_html))             # <-- actually display it\n",
        "    print(out[\"response\"][\"meta_data\"][\"theta_hat\"],\n",
        "          out[\"response\"][\"meta_data\"][\"avg_reward\"])\n"
      ],
      "metadata": {
        "id": "UI0S7pWtMNUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HTML(json.loads(out['response']['data']).get('figure'))"
      ],
      "metadata": {
        "id": "cHRMyYKxMp9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  2PL, item dict pool with discrimination"
      ],
      "metadata": {
        "id": "i5rntwxEPU41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from IPython.display import display, HTML\n",
        "items_2pl = [\n",
        "    {\"label\": \"Q1\", \"b\": 0.35, \"a\": 3.5},\n",
        "    {\"label\": \"Q2\", \"b\": 0.50, \"a\": 4.0},\n",
        "    {\"label\": \"Q3\", \"b\": 0.70, \"a\": 5.0},\n",
        "]\n",
        "\n",
        "irp2 = ItemResponsePrediction(likelihood=\"2pl\", engine=\"bayes\", policy=\"thompson\", items=items_2pl)\n",
        "rec = irp2.recommend()\n",
        "print(\"Recommend:\", rec[\"response\"][\"meta_data\"][\"item\"])  # inspect choice\n",
        "\n",
        "# Suppose user answered Q2 incorrectly (0)\n",
        "out = irp2.update_estimator(\"Q2\", 0)\n",
        "fig_html = json.loads(out[\"response\"][\"data\"])[\"figure\"]\n",
        "display(HTML(fig_html))\n",
        "print(\"theta(mean):\", out[\"response\"][\"meta_data\"][\"theta_hat\"])"
      ],
      "metadata": {
        "id": "bs9veVeSPV6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reset with a new pool and prior"
      ],
      "metadata": {
        "id": "l8FIiHVDNjnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_items = [\n",
        "    {\"label\": \"N1\", \"b\": 0.40, \"kappa\": 50.0, \"gamma\": 0.0},\n",
        "    {\"label\": \"N2\", \"b\": 0.60, \"kappa\": 50.0, \"gamma\": 0.0},\n",
        "]\n",
        "\n",
        "r = irp.reset_estimator(alpha=2.0, beta=2.0, items=new_items, likelihood=\"ideal\")\n",
        "fig_html = json.loads(out[\"response\"][\"data\"])[\"figure\"]\n",
        "display(HTML(fig_html))             # <-- actually display it\n",
        "print(out[\"response\"][\"meta_data\"][\"theta_hat\"],\n",
        "      out[\"response\"][\"meta_data\"][\"avg_reward\"])\n",
        "print(r[\"status\"], r[\"response\"][\"meta_data\"][\"posterior_summary\"])"
      ],
      "metadata": {
        "id": "dkYG1TcfNm_g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}